{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Cell Me Competition\n",
    "## I Summary\n",
    "### Dataset\n",
    "\n",
    "## II Analysis\n",
    "### 2.1. Download dataset\n",
    "If you're in Kaggle ![CellMe](https://www.kaggle.com/c/cell-me) competition and have installed kaggle api you can use below code to download dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "wdir = os.getcwd()\n",
    "\n",
    "if not os.path.isfile(wdir+\"/data/train.csv.zip\"):\n",
    "    os.popen(\"~/.local/bin/kaggle competitions download -p ./data cell-me\").read()\n",
    "    \n",
    "if not os.path.isfile(wdir+\"/data/test.csv\"):\n",
    "    with zipfile.ZipFile(wdir +\"/data/test.csv.zip\",\"r\") as zip_ref:\n",
    "        zip_ref.extractall(wdir+\"/data\")\n",
    "        \n",
    "if not os.path.isfile(wdir+\"/data/train.csv\"):\n",
    "    with zipfile.ZipFile(wdir +\"/data/train.csv.zip\",\"r\") as zip_ref:\n",
    "        zip_ref.extractall(wdir+\"/data\")\n",
    "\n",
    "test_file_path = \"data/test.csv\"\n",
    "train_file_path = \"data/train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "import logging\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#visualization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Pieces of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.0 Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(23)\n",
    "seed = 23\n",
    "num_of_topics = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(file_path,sample=False,nrows=1000):\n",
    "    global wdir\n",
    "    if not sample:\n",
    "        return pd.read_csv(wdir+\"/\"+file_path,sep=\",\",header=0)\n",
    "    return pd.read_csv(wdir+\"/\"+file_path,sep=\",\",header=0,nrows=nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer():\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Useful regexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_EMOTICON = re.compile('(:\\)|:-\\)|:\\(|:-\\(|;\\);-\\)|:-O|8-|:P|:D|:\\||:S|:\\$|:@|8o\\||\\+o\\(|\\(H\\)|\\(C\\)|\\(\\?\\))')\n",
    "RE_HTTP = re.compile(\"http(s)?://[/\\.a-z0-9]+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3. Word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordTokenizer(Tokenizer):\n",
    "    def tokenize(text):\n",
    "        words = str(text).lower().split()\n",
    "        return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4. Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"a\", \"about\", \"after\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\",\n",
    "            \"before\", \"being\", \"between\", \"both\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"during\", \"each\",\n",
    "            \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\",\n",
    "            \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\",\n",
    "            \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"of\",\n",
    "            \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"own\", \"shan't\", \"she\", \"she'd\",\n",
    "            \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\",\n",
    "            \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\",\n",
    "            \"they've\", \"this\", \"those\", \"through\", \"to\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\",\n",
    "            \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
    "            \"which\", \"while\", \"who\", \"who's\", \"whom\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "            \"your\", \"yours\", \"yourself\", \"yourselves\", \"above\", \"again\", \"against\", \"aren't\", \"below\", \"but\", \"can't\",\n",
    "            \"cannot\", \"couldn't\", \"didn't\", \"doesn't\", \"don't\", \"down\", \"few\", \"hadn't\", \"hasn't\", \"haven't\", \"if\",\n",
    "            \"isn't\", \"mustn't\", \"no\", \"nor\", \"not\", \"off\", \"out\", \"over\", \"shouldn't\", \"same\", \"too\", \"under\", \"why\",\n",
    "            \"why's\", \"won't\", \"wouldn't\",\",\",\".\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5. Review tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewTokenizer(WordTokenizer):\n",
    "    def tokenize(text,stopwords):\n",
    "        tokens = super(ReviewTokenizer, ReviewTokenizer).tokenize(text)\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            token = tokens[i]\n",
    "            matches = RE_EMOTICON.search(token)\n",
    "            if matches:\n",
    "                emoticon = matches.group(0)\n",
    "                newTokens = token.split(emoticon)\n",
    "                tokens[i] = emoticon\n",
    "                tokens.extend(newTokens)\n",
    "            else:\n",
    "                del tokens[i]\n",
    "                tokens[i:i] = nltk.word_tokenize(token)\n",
    "          \n",
    "            i = i + 1\n",
    "        return [word for word in tokens if word not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5. Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Ph.D. D.B. tutorial\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_color_codes(\"muted\")\n",
    "\n",
    "def show_histogram(word_counts, title=None):\n",
    "    plot_df = pd.DataFrame.from_dict(word_counts,orient=\"index\").reset_index().rename(columns={0:'Count'})\n",
    "    f, ax = plt.subplots(figsize=(12, 15))\n",
    "    p = sns.barplot(x=\"Count\", y=\"index\", data=plot_df, color=\"b\")\n",
    "    p.set(xlabel=\"Count\", ylabel=\"\", title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.6 Remove once-occur words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = defaultdict(int)\n",
    "def _remove_once_occurence_words(text):\n",
    "    global frequency;\n",
    "    return [token for token in text if token in frequency and frequency[token]>1]\n",
    "\n",
    "def remove_once_occurence_words(texts):\n",
    "    global frequency\n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency[token] += 1\n",
    "    texts = [[token for token in text if frequency[token] > 1]\n",
    "        for text in texts]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.7 Build dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dictionary(unique_texts):\n",
    "    dictionary = corpora.Dictionary(unique_texts)\n",
    "    dictionary.save('tmp/dictionary.dict')\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.8 Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_corpus(unique_texts,dictionary):\n",
    "    corpus = [dictionary.doc2bow(text) for text in unique_texts]\n",
    "    #it's very important to save\n",
    "    corpora.MmCorpus.serialize('tmp/corpus.mm', corpus)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.9 Build lda model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_topic_model(corpus,id2word,num_topics=10,passes=20):\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    #lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics, update_every=0, passes=passes)\n",
    "    lda = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word, num_topics=num_topics, passes=passes)\n",
    "    return lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.10 Replace texts with topic prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dealing_with_reviews(data,stopwords,num_of_topics):\n",
    "    texts = list([])\n",
    "    for i in data.index:\n",
    "        tokens = ReviewTokenizer.tokenize(data.Reviews.iat[i],stopwords)\n",
    "        texts.append(tokens)\n",
    "    \n",
    "    texts = remove_once_occurence_words(texts)\n",
    "    dictionary = build_dictionary(texts)\n",
    "    corpus = build_corpus(texts,dictionary)\n",
    "    lda = build_topic_model(corpus, dictionary,num_topics=num_of_topics)\n",
    "    empty_dict = {range(0,num_of_topics):0}\n",
    "    \n",
    "    slen = len(data['Reviews'])\n",
    "    for j in range(0,num_of_topics):\n",
    "        data['topic_'+str(j)] = pd.Series(range(0,slen),index=data.index,dtype=float)\n",
    "    \n",
    "    \n",
    "    for i in data.index:\n",
    "        tokens = ReviewTokenizer.tokenize(data.Reviews.iat[i],stopwords)\n",
    "        unique_tokens = _remove_once_occurence_words(tokens)\n",
    "        new_mm = dictionary.doc2bow(unique_tokens)\n",
    "        topics = dict(lda[new_mm])\n",
    "        for j in range(0,num_of_topics):\n",
    "            if (not j in topics):\n",
    "                data['topic_'+str(j)].iat[i] = 0\n",
    "            else:\n",
    "                data['topic_'+str(j)].iat[i] = topics[j]\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.0 Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = loader(train_file_path)\n",
    "#counter = Counter()\n",
    "#for i in data.index:\n",
    "#    words = ReviewTokenizer.tokenize(data.Reviews.iat[i])\n",
    "#    counter.update(words);\n",
    "\n",
    "# full data is too large\n",
    "#show_histogram(counter,\"Words frequency\")\n",
    "#import csv\n",
    "#my_dict = dict(counter)\n",
    "\n",
    "#with open('mycsvfile.csv', 'w') as f:  # Just use 'w' mode in 3.x\n",
    "#    w = csv.writer(f)\n",
    "#    w.writerow(my_dict.keys())\n",
    "#    w.writerow(my_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "data = loader(train_file_path)\n",
    "\n",
    "data = dealing_with_reviews(data,stopwords,num_of_topics)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y = pd.factorize(data['Rating'])[0]\n",
    "data['Product Name'] = pd.factorize(data['Product Name'])[0]\n",
    "data['Brand Name'] = pd.factorize(data['Product Name'])[0]\n",
    "features = data.columns[:11].drop(['Rating','Reviews','Id'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], y, test_size = 0.25, random_state = seed)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1,  random_state=seed)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "errors = abs(predictions - y_test)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "print('RMSE:', mean_squared_error(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
